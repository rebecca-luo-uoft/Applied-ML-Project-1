{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833c2be2-3140-41f5-b09f-9946a2179d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ssuid', 'spanel', 'swave', 'srefmon', 'rhcalmn', 'rhcalyr', 'tfipsst', 'epppnum', 'esex', 'wpfinwgt', 'tage', 'eeducate', 'rmesr', 'birth_month', 'sippid', 'months', 'date', 'birth', 'birth_seen_f', 'birth_seen', 'ref_month_ns', 'ref_month', 'state', 'end_date', 'end_weight_f', 'end_weight', 'CA_date', 'NJ_date', 'post_policy', 'rm_lfp', 'working', 'looking', 'lt_college_f', 'lt_college', 'Birth', '_IBirth_2', '_IBirth_3', '_IBirth_4', '_IBirth_5', '_IBirth_6', '_IBirth_7', '_IBirth_8', '_IBirth_9', '_IBirth_10', '_IBirth_11', '_IBirth_12', '_IBirth_13', '_IBirth_14', '_IBirth_15', '_IBirth_16', '_IBirth_17', '_IBirth_18', '_IBirth_19', '_IBirth_20', '_IBirth_21', '_IBirth_22', '_IBirth_23', '_IBirth_24', '_IBirth_25', '_IBirth_26', '_IBirth_27', '_IBirth_28', '_IBirth_29', '_IBirth_30', '_IBirth_31', '_IBirth_32', '_IBirth_33', '_IBirth_34', '_IBirth_35', '_IBirth_36', '_IBirth_37', '_IBirth_38', '_IBirth_39', '_IBirth_40', '_IBirth_41', '_IBirth_42', '_IBirth_43', '_IBirth_44', '_IBirth_45', '_IBirth_46', '_IBirth_47', '_IBirth_48', '_IBirth_49', '_IBirth_50', '_IBirth_51', '_Ipost_poli_1', '_IBirXpos_2_1', '_IBirXpos_3_1', '_IBirXpos_4_1', '_IBirXpos_5_1', '_IBirXpos_6_1', '_IBirXpos_7_1', '_IBirXpos_8_1', '_IBirXpos_9_1', '_IBirXpos_10_1', '_IBirXpos_11_1', '_IBirXpos_12_1', '_IBirXpos_13_1', '_IBirXpos_14_1', '_IBirXpos_15_1', '_IBirXpos_16_1', '_IBirXpos_17_1', '_IBirXpos_18_1', '_IBirXpos_19_1', '_IBirXpos_20_1', '_IBirXpos_21_1', '_IBirXpos_22_1', '_IBirXpos_23_1', '_IBirXpos_24_1', '_IBirXpos_25_1', '_IBirXpos_26_1', '_IBirXpos_27_1', '_IBirXpos_28_1', '_IBirXpos_29_1', '_IBirXpos_30_1', '_IBirXpos_31_1', '_IBirXpos_32_1', '_IBirXpos_33_1', '_IBirXpos_34_1', '_IBirXpos_35_1', '_IBirXpos_36_1', '_IBirXpos_37_1', '_IBirXpos_38_1', '_IBirXpos_39_1', '_IBirXpos_40_1', '_IBirXpos_41_1', '_IBirXpos_42_1', '_IBirXpos_43_1', '_IBirXpos_44_1', '_IBirXpos_45_1', '_IBirXpos_46_1', '_IBirXpos_47_1', '_IBirXpos_48_1', '_IBirXpos_49_1', '_IBirXpos_50_1', '_IBirXpos_51_1', 'lBirth', '_LlBirth_2', '_LlBirth_8', '_LlBirth_9', '_LlBirth_10', '_LlBirth_11', '_LlBirth_12', '_LlBirth_13', '_LlBirth_14', '_LlBirth_15', '_LlBirth_16', '_LlBirth_17', '_LlBirth_18', '_LlBirth_19', '_LlBirth_20', '_LlBirth_21', '_LlBirth_22', '_LlBirth_23', '_LlBirth_24', '_LlBirth_25', '_LlBirth_26', '_LlBirth_27', '_LlBirth_28', '_LlBirth_29', '_LlBirth_30', '_LlBirth_31', '_LlBirth_32', '_LlBirth_33', '_LlBirth_34', '_LlBirth_35', '_LlBirth_36', '_LlBirth_37', '_LlBirth_38', '_LlBirth_39', '_LlBirth_40', '_LlBirth_41', '_LlBirth_42', '_LlBirth_43', '_LlBirth_44', '_LlBirth_45', '_LlBirth_46', '_LlBirth_47', '_LlBirth_48', '_LlBirth_49', '_LlBirth_50', '_Lpost_poli_1', '_LlBiXpos_2_1', '_LlBiXpos_8_1', '_LlBiXpos_9_1', '_LlBiXpos_10_1', '_LlBiXpos_11_1', '_LlBiXpos_12_1', '_LlBiXpos_13_1', '_LlBiXpos_14_1', '_LlBiXpos_15_1', '_LlBiXpos_16_1', '_LlBiXpos_17_1', '_LlBiXpos_18_1', '_LlBiXpos_19_1', '_LlBiXpos_20_1', '_LlBiXpos_21_1', '_LlBiXpos_22_1', '_LlBiXpos_23_1', '_LlBiXpos_24_1', '_LlBiXpos_25_1', '_LlBiXpos_26_1', '_LlBiXpos_27_1', '_LlBiXpos_28_1', '_LlBiXpos_29_1', '_LlBiXpos_30_1', '_LlBiXpos_31_1', '_LlBiXpos_32_1', '_LlBiXpos_33_1', '_LlBiXpos_34_1', '_LlBiXpos_35_1', '_LlBiXpos_36_1', '_LlBiXpos_37_1', '_LlBiXpos_38_1', '_LlBiXpos_39_1', '_LlBiXpos_40_1', '_LlBiXpos_41_1', '_LlBiXpos_42_1', '_LlBiXpos_43_1', '_LlBiXpos_44_1', '_LlBiXpos_45_1', '_LlBiXpos_46_1', '_LlBiXpos_47_1', '_LlBiXpos_48_1', '_LlBiXpos_49_1', '_LlBiXpos_50_1', 'age_group', 'birth_month_str', 'birth_year_month_date', 'birth_year_recession', 'recession_birth']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.formula.api import ols\n",
    "from linearmodels.panel import PanelOLS\n",
    "\n",
    "\n",
    "file_path = '/Users/rebeccluo/Downloads/US_Paid_leave_analysis.dta'\n",
    "\n",
    "# Load the file into a DataFrame\n",
    "df = pd.read_stata(file_path)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0a65fb-73f6-45e4-9a15-e05cf0a3e258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2816, 231)\n"
     ]
    }
   ],
   "source": [
    "unique_data = df.drop_duplicates(subset='sippid').dropna(subset=['rm_lfp'])\n",
    "print(unique_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb640dee-99f3-457b-bb1b-add20a7c9481",
   "metadata": {},
   "outputs": [],
   "source": [
    "birth_vars = [f'_IBirth_{i}' for i in range(2, 52)]  # Birth dummies from _IBirth_2 to _IBirth_51\n",
    "birxpos_vars = [f'_IBirXpos_{i}_1' for i in range(2, 52)]  # Event-study dummies _IBirXpos_2_1 to _IBirXpos_50_1\n",
    "llbirth_vars = [f'_LlBirth_{2}_1'] + [f'_LlBirth_{i}_1' for i in range(8, 51)]   # Reference period dummies from _LlBirth_8 to _LlBirth_50\n",
    "llbipos_vars = [f'_LlBiXpos_{2}_1'] + [f'_LlBiXpos_{i}_1' for i in range(8, 51)]  # Event-study reference period _LlBiXpos_8_1 to _LlBiXpos_50_1, what we are interested in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9b795af-692b-494f-9136-f8c000cad6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2816, 95)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    year_dummies = pd.get_dummies(unique_data['rhcalyr'], drop_first=True)  # Time dummy for year\n",
    "    birth_dummies = pd.get_dummies(unique_data[birth_vars], drop_first=False)  # Dummies for birth_vars\n",
    "    state_dummies = pd.get_dummies(unique_data['state'], drop_first=True)  # Dummies for states (assuming 'state' column)\n",
    "    sippid_dummies = pd.get_dummies(unique_data['sippid'], prefix='sippid', drop_first=True)\n",
    "    month_dummies = pd.get_dummies(unique_data['ref_month'], prefix='month', drop_first=True)\n",
    "    edu_dummies = pd.get_dummies(unique_data['lt_college'], prefix='college', drop_first=True)\n",
    "    age_group_dummies = pd.get_dummies(unique_data['age_group'],prefix='age', drop_first=True)  # Dummies for age groups\n",
    "    recession_dummies = pd.get_dummies(unique_data['recession_birth'],prefix='recession', drop_first=True)  # Dummies for recession years\n",
    "\n",
    "    \n",
    "    age_recession_interactions = pd.DataFrame(index=unique_data.index)\n",
    "    for age_col in age_group_dummies.columns:\n",
    "        for recession_col in recession_dummies.columns:\n",
    "            interaction_name = f'{age_col}_recession_{recession_col}'\n",
    "            age_recession_interactions[interaction_name] = age_group_dummies[age_col] * recession_dummies[recession_col]\n",
    "\n",
    "\n",
    "\n",
    "    # Step 2: Create interaction terms between birth_vars and time (rhcalyr)\n",
    "    birth_time_interactions = pd.DataFrame(index=unique_data.index)\n",
    "    for birth_col in birth_dummies.columns:\n",
    "        for year_col in year_dummies.columns:\n",
    "            interaction_name = f'{birth_col}_time_{year_col}'\n",
    "            birth_time_interactions[interaction_name] = birth_dummies[birth_col] * year_dummies[year_col]\n",
    "\n",
    "    # Step 3: Create interaction terms between birth_vars and state\n",
    "    birth_state_interactions = pd.DataFrame(index=unique_data.index)\n",
    "    for birth_col in birth_dummies.columns:\n",
    "        for state_col in state_dummies.columns:\n",
    "            interaction_name = f'{birth_col}_state_{state_col}'\n",
    "            birth_state_interactions[interaction_name] = birth_dummies[birth_col] * state_dummies[state_col]\n",
    "            \n",
    "    state_edu_interactions = pd.DataFrame(index=unique_data.index)\n",
    "    for state_col in state_dummies.columns:\n",
    "        for edu_col in edu_dummies.columns:\n",
    "            interaction_name = f'{state_col}_edu_{edu_col}'  # Name the interaction term\n",
    "            state_edu_interactions[interaction_name] = state_dummies[state_col] * edu_dummies[edu_col]\n",
    "\n",
    "    state_year_interactions = pd.DataFrame(index=unique_data.index)\n",
    "    for state_col in state_dummies.columns:\n",
    "        for year_col in year_dummies.columns:\n",
    "            interaction_name = f'{state_col}_time_{year_col}'\n",
    "            state_year_interactions[interaction_name] = state_dummies[state_col] * year_dummies[year_col]\n",
    "\n",
    "X = pd.concat([year_dummies,state_dummies,age_group_dummies,\n",
    "    recession_dummies,age_recession_interactions,month_dummies,state_year_interactions,edu_dummies], axis=1)\n",
    "\n",
    "#no missing values\n",
    "X = X.fillna(0)\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "#complete feature matrix ready for analysis or modeling\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "858206e4-f693-435a-a728-571c445bb16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the propensity data DataFrame: (2816, 97)\n",
      "    1996   1997   1998   1999   2000   2001   2002   2003   2004   2005  ...  \\\n",
      "0  False  False   True  False  False  False  False  False  False  False  ...   \n",
      "1  False  False   True  False  False  False  False  False  False  False  ...   \n",
      "2  False  False  False   True  False  False  False  False  False  False  ...   \n",
      "3   True  False  False  False  False  False  False  False  False  False  ...   \n",
      "4  False   True  False  False  False  False  False  False  False  False  ...   \n",
      "\n",
      "   Texas_time_2006  Texas_time_2007  Texas_time_2008  Texas_time_2009  \\\n",
      "0            False            False            False            False   \n",
      "1            False            False            False            False   \n",
      "2            False            False            False            False   \n",
      "3            False            False            False            False   \n",
      "4            False            False            False            False   \n",
      "\n",
      "   Texas_time_2010  Texas_time_2011  Texas_time_2012  college_1.0  rm_lfp  \\\n",
      "0            False            False            False        False     1.0   \n",
      "1            False            False            False         True     0.0   \n",
      "2            False            False            False         True     0.0   \n",
      "3            False            False            False         True     1.0   \n",
      "4            False            False            False         True     1.0   \n",
      "\n",
      "   post_policy  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          0.0  \n",
      "4          0.0  \n",
      "\n",
      "[5 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = X.reset_index(drop=True)\n",
    "\n",
    "#Create a DataFrame for the outcome and treatment variables\n",
    "outcome_treatment_df = pd.DataFrame({\n",
    "    'rm_lfp': unique_data['rm_lfp'].values,           # Outcome variable\n",
    "    'post_policy': unique_data['post_policy'].values   # Treatment variable\n",
    "})\n",
    "\n",
    "#Concatenate the feature matrix \n",
    "if isinstance(X, list):\n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "propensity_data = pd.concat([X, outcome_treatment_df], axis=1)\n",
    "outcome_treatment_df = outcome_treatment_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"Shape of the propensity data DataFrame:\", propensity_data.shape)\n",
    "print(propensity_data.head())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6eda9d61-f75c-4b6f-af4b-682e9f41be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: 0.061738022002769344\n",
      "Weighted Treated Mean: 0.6550119237328784\n",
      "Weighted Control Mean: 0.5932739017301091\n",
      "Propensity Scores: [0.00127469 0.00228141 0.0013607  ... 0.99355231 0.99023292 0.00106997]\n",
      "Stabilized Weights: [0.85435166 0.85521371 0.85442524 ... 6.1904165  6.21116762 0.85417657]\n",
      "Treatment Probability: 0.15518465638160706\n",
      "\n",
      "Diagnostics:\n",
      "Mean of stabilized weights: 2.0000\n",
      "Std of stabilized weights: 2.9694\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def inverse_probability_weighting(outcome_treatment_df, X, outcome_variable='rm_lfp', treatment_variable='post_policy'):\n",
    "   \n",
    "\n",
    "    treated = outcome_treatment_df[treatment_variable].values\n",
    "    \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Estimate propensity scores using logistic regression\n",
    "    log_reg = LogisticRegression(\n",
    "        solver='liblinear',  # Good for small datasets\n",
    "        class_weight='balanced',  # Handles imbalanced treatment groups\n",
    "        random_state=42  # For reproducibility\n",
    "    )\n",
    "    log_reg.fit(X_scaled, treated)\n",
    "    \n",
    "    # Compute propensity scores \n",
    "    propensity_scores = log_reg.predict_proba(X_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate Stabilized Weights\n",
    "    # Compute inverse probability weights\n",
    "    treated_weight = treated / propensity_scores\n",
    "    control_weight = (1 - treated) / (1 - propensity_scores)\n",
    "    \n",
    "    # Stabilize weights\n",
    "    p_treatment = np.mean(treated)\n",
    "    stabilized_weights = np.where(\n",
    "        treated == 1, \n",
    "        treated_weight / np.mean(treated_weight),  # Stabilized weights for treated\n",
    "        control_weight / np.mean(control_weight)   # Stabilized weights for control\n",
    "    )\n",
    "    \n",
    "    # Compute Weighted Outcomes\n",
    "    outcome = outcome_treatment_df[outcome_variable].values\n",
    "    \n",
    "    # Compute weighted mean outcomes\n",
    "    weighted_treated_mean = np.average(\n",
    "        outcome[treated == 1], \n",
    "        weights=stabilized_weights[treated == 1]\n",
    "    )\n",
    "    \n",
    "    weighted_control_mean = np.average(\n",
    "        outcome[treated == 0], \n",
    "        weights=stabilized_weights[treated == 0]\n",
    "    )\n",
    "    \n",
    "    # Compute ATE\n",
    "    ate = weighted_treated_mean - weighted_control_mean\n",
    "    \n",
    "    # Additional diagnostics\n",
    "    return {\n",
    "        'ATE': ate,\n",
    "        'Weighted Treated Mean': weighted_treated_mean,\n",
    "        'Weighted Control Mean': weighted_control_mean,\n",
    "        'Propensity Scores': propensity_scores,\n",
    "        'Stabilized Weights': stabilized_weights,\n",
    "        'Treatment Probability': p_treatment\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    results = inverse_probability_weighting(\n",
    "        outcome_treatment_df, \n",
    "        X, \n",
    "        outcome_variable='rm_lfp', \n",
    "        treatment_variable='post_policy'\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    for key, value in results.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    # Diagnostics \n",
    "    print(\"\\nDiagnostics:\")\n",
    "    print(f\"Mean of stabilized weights: {np.mean(results['Stabilized Weights']):.4f}\")\n",
    "    print(f\"Std of stabilized weights: {np.std(results['Stabilized Weights']):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
